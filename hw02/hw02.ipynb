{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_banknote_authentication.txt\")\n",
    "df = df.sample(frac=1)\n",
    "data = df.values\n",
    "# 80/20 split\n",
    "train_split = (data[:int(data.shape[0]*.8), :data.shape[1]-1], data[:int(data.shape[0]*.8), data.shape[1]-1])\n",
    "test_split = (data[int(data.shape[0]*.8):, :data.shape[1]-1], data[int(data.shape[0]*.8):, data.shape[1]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classification F1 Score: 0.9796\n",
      "Adjusted Classification F1 Score: 0.9796\n"
     ]
    }
   ],
   "source": [
    "baseline_classification_tree = tree.DecisionTreeClassifier()\n",
    "adjust_classification_tree = tree.DecisionTreeClassifier(max_features=4, min_samples_split = 4, max_depth = 30)\n",
    "clf = baseline_classification_tree.fit(train_split[0], train_split[1])\n",
    "pred = clf.predict(test_split[0])\n",
    "print(f\"Baseline Classification F1 Score: {metrics.f1_score(test_split[1], pred):.4f}\")\n",
    "clf = adjust_classification_tree.fit(train_split[0], train_split[1])\n",
    "pred = clf.predict(test_split[0])\n",
    "print(f\"Adjusted Classification F1 Score: {metrics.f1_score(test_split[1], pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no significant change seen when tuning the parameters of the model. The banknote dataset is easily seperatable and not sensitive to tuning hyperparameters. When the dataset was trained on the logistic regression model, loss converged after several epochs didnt suffer much from overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1 Score: 0.992 (0.008)\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = ensemble.RandomForestClassifier(n_estimators=100, max_depth=100, min_samples_split=2)\n",
    "clf = forest_classifier.fit(train_split[0], train_split[1])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(clf, data[:,:data.shape[1]-1], data[:,data.shape[1]-1], scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Random Forest F1 Score: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost F1 Score: 0.997 (0.005)\n"
     ]
    }
   ],
   "source": [
    "gradient_boost = ensemble.GradientBoostingClassifier(loss=\"log_loss\", learning_rate=.2) \n",
    "clf = gradient_boost.fit(train_split[0], train_split[1])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(clf, data[:,:data.shape[1]-1], data[:,data.shape[1]-1], scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Gradient Boost F1 Score: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient Boost algorithm has a marginally higher mean F1 Score and a lower std for K fold cross validation. This means that the gradient boost model did slightly, but not significantly better than random forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the task for this project is to identify fake bank notes, precision would have been a good metric because it shows how likely it is for a genuine bank note to be flagged as fake. Flagging real bank notes as fake is very bad because it would mean that innocent people are being accused of a false crime. In addition, recall is a good metric because the primary goal of this task if finding fake bank notes. F1 score combines precision and recall to create a metric that evaluates the performance of the model on both of these categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9818\n",
      "Random Forest Accuracy : 0.9891\n",
      "Gradient Boost Accuracy : 0.9964\n"
     ]
    }
   ],
   "source": [
    "baseline_classification_tree = tree.DecisionTreeClassifier()\n",
    "clf = baseline_classification_tree.fit(train_split[0], train_split[1])\n",
    "pred = clf.predict(test_split[0])\n",
    "print(f\"Baseline Accuracy: {np.sum(pred == test_split[1])/test_split[1].shape[0]:.4f}\")\n",
    "forest_classifier = ensemble.RandomForestClassifier(n_estimators=100, max_depth=100, min_samples_split=2)\n",
    "clf = forest_classifier.fit(train_split[0], train_split[1])\n",
    "pred = clf.predict(test_split[0])\n",
    "print(f\"Random Forest Accuracy : {np.sum(pred == test_split[1])/test_split[1].shape[0]:.4f}\")\n",
    "gradient_boost = ensemble.GradientBoostingClassifier(loss=\"log_loss\", learning_rate=.2) \n",
    "clf = gradient_boost.fit(train_split[0], train_split[1])\n",
    "pred = clf.predict(test_split[0])\n",
    "print(f\"Gradient Boost Accuracy : {np.sum(pred == test_split[1])/test_split[1].shape[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I chose F1 score as my metric, using any of the popular metrics would have been just as effective because my dataset is balanced and highly seperatable. As shown above, using the accuracy metric yields similar scores as F1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0be73a0e6356a5a1c38dc53f1e67790b18ed332d277068fed34d2daa61958429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
