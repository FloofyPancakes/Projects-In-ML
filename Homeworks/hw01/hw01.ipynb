{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project attempts to seperate genuine and forged banknotes using logistic regresion. The dataset for this project is taken from *https://archive.ics.uci.edu/ml/datasets/banknote+authentication*. \n",
    "\n",
    "The curators of the dataset preprocessed 400 x 400 pixel banknote images using Wavelet Transformation to extract the following features: variance, skewness, curtosis, entopy.  \n",
    "\n",
    "Since this task requires seperating banknotes into two categories, logistic regression will be the best algorithm for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.6216</th>\n",
       "      <th>8.6661</th>\n",
       "      <th>-2.8073</th>\n",
       "      <th>-0.44699</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.36840</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.9606</td>\n",
       "      <td>-3.16250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       3.6216    8.6661  -2.8073  -0.44699  0\n",
       "0     4.54590   8.16740  -2.4586  -1.46210  0\n",
       "1     3.86600  -2.63830   1.9242   0.10645  0\n",
       "2     3.45660   9.52280  -4.0112  -3.59440  0\n",
       "3     0.32924  -4.45520   4.5718  -0.98880  0\n",
       "4     4.36840   9.67180  -3.9606  -3.16250  0\n",
       "...       ...       ...      ...       ... ..\n",
       "1366  0.40614   1.34920  -1.4501  -0.55949  1\n",
       "1367 -1.38870  -4.87730   6.4774   0.34179  1\n",
       "1368 -3.75030 -13.45860  17.5932  -2.77710  1\n",
       "1369 -3.56370  -8.38270  12.3930  -1.28230  1\n",
       "1370 -2.54190  -0.65804   2.6842   1.19520  1\n",
       "\n",
       "[1371 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "link to dataset: https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "'''\n",
    "df = pd.read_csv(\"data_banknote_authentication.txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.6216</th>\n",
       "      <th>8.6661</th>\n",
       "      <th>-2.8073</th>\n",
       "      <th>-0.44699</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1.50770</td>\n",
       "      <td>1.9596</td>\n",
       "      <td>-3.05840</td>\n",
       "      <td>-0.12243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3.92320</td>\n",
       "      <td>-3.2467</td>\n",
       "      <td>3.45790</td>\n",
       "      <td>0.83705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>-3.89530</td>\n",
       "      <td>4.0392</td>\n",
       "      <td>-0.30190</td>\n",
       "      <td>-2.18360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>-0.46651</td>\n",
       "      <td>2.3383</td>\n",
       "      <td>-2.98120</td>\n",
       "      <td>-1.04310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1.91050</td>\n",
       "      <td>8.8710</td>\n",
       "      <td>-2.33860</td>\n",
       "      <td>-0.75604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-1.30000</td>\n",
       "      <td>10.2678</td>\n",
       "      <td>-2.95300</td>\n",
       "      <td>-5.86380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>4.34350</td>\n",
       "      <td>3.3295</td>\n",
       "      <td>0.83598</td>\n",
       "      <td>0.64955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>-5.52500</td>\n",
       "      <td>6.3258</td>\n",
       "      <td>0.89768</td>\n",
       "      <td>-6.62410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>-1.75890</td>\n",
       "      <td>-6.4624</td>\n",
       "      <td>8.47730</td>\n",
       "      <td>0.31981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-0.88728</td>\n",
       "      <td>2.8080</td>\n",
       "      <td>-3.14320</td>\n",
       "      <td>-1.20350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       3.6216   8.6661  -2.8073  -0.44699  0\n",
       "1032  1.50770   1.9596 -3.05840  -0.12243  1\n",
       "142   3.92320  -3.2467  3.45790   0.83705  0\n",
       "1304 -3.89530   4.0392 -0.30190  -2.18360  1\n",
       "992  -0.46651   2.3383 -2.98120  -1.04310  1\n",
       "372   1.91050   8.8710 -2.33860  -0.75604  0\n",
       "...       ...      ...      ...       ... ..\n",
       "218  -1.30000  10.2678 -2.95300  -5.86380  0\n",
       "567   4.34350   3.3295  0.83598   0.64955  0\n",
       "1324 -5.52500   6.3258  0.89768  -6.62410  1\n",
       "1123 -1.75890  -6.4624  8.47730   0.31981  1\n",
       "1236 -0.88728   2.8080 -3.14320  -1.20350  1\n",
       "\n",
       "[1371 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for preprocessing, we must randomize the dataset so we get an even distribution of labels for training\n",
    "and testing split\n",
    "'''\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c9c0dc8370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "By simply averaging each banknotes features, we can observe a binary split when plotting the points.\n",
    "Based on this, we can confirm that the features we use are good\n",
    "'''\n",
    "y = torch.from_numpy(df.values)\n",
    "y = torch.sum(y, dim=1)\n",
    "x = torch.arange(0, y.shape[0])\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_features, device = f\"cuda:0\"):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        '''\n",
    "        binary classification using Logistic Regression,\n",
    "        num_features = number of features\n",
    "        '''\n",
    "        self.w = nn.Parameter(torch.randn(num_features, 1, device = device), requires_grad=True)   # (n x 1)\n",
    "        self.b = nn.Parameter(torch.randn(1,1, device = device), requires_grad=True)   # (1 x 1)\n",
    "        self.n = num_features\n",
    "    \n",
    "    def sigmoid(self, a):\n",
    "        '''\n",
    "        custom sigmoid function\n",
    "        '''\n",
    "        return 1/(1+(torch.exp(-a)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        X is (batch_size x n)\n",
    "        '''\n",
    "        X = X.T # (n x batch_size)\n",
    "        A = self.sigmoid(torch.matmul(self.w.T, X) + self.b)  # (1 x batch_size)\n",
    "        return A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(X, A, Y):\n",
    "    '''\n",
    "    cost function\n",
    "    \n",
    "    X = features,\n",
    "    A = predicted labels,\n",
    "    Y = actual labels\n",
    "    '''\n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "    A = A.T\n",
    "    n = X.shape[0]\n",
    "    cost = -torch.sum(Y*torch.log(A) + (1-Y)*torch.log(1-A))\n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "    return cost \n",
    "\n",
    "def update_grad(X, A, Y, params):\n",
    "    '''\n",
    "    calculates/updates the gradient of the cost function\n",
    "\n",
    "    X = features\n",
    "    A = predicted labels,\n",
    "    Y = actual labels\n",
    "    '''\n",
    "    w = next(params)\n",
    "    b = next(params)\n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "    A = A.T\n",
    "    n = X.shape[0]\n",
    "    cost = -torch.sum(Y*torch.log(A) + (1-Y)*torch.log(1-A))  # loss\n",
    "    w.grad = torch.matmul(X, (A-Y).T) / n  # update gradient of weights, (n x 1)\n",
    "    b.grad = (torch.sum(A-Y, dim=1).unsqueeze(dim=-1)) / n            # update gradient of bias, (1, 1)\n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "    return cost \n",
    "\n",
    "def gradient_descent(params, learning_rate):\n",
    "    '''\n",
    "    performs updates the values of the weights and bias using vanilla gradient descent,\n",
    "    params = learnable parameters of model\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        for p in params:\n",
    "            p -= learning_rate * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = f\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using device: {device}\")\n",
    "mini_batch_size = 64\n",
    "num_features = df.shape[1] - 1\n",
    "epochs = 20\n",
    "\n",
    "vanilla_grad_model = LogisticRegression(num_features)\n",
    "mini_batch_grad_model = LogisticRegression(num_features)\n",
    "Adam_model = LogisticRegression(num_features)\n",
    "RMSprop_model = LogisticRegression(num_features)\n",
    "\n",
    "\n",
    "train_loader = du.DataLoader(dataset=torch.from_numpy(df[:df.shape[0]*8 // 10].values).float(),\n",
    "                             batch_size=df.shape[0],  # batch_size is the length of the entire dataset\n",
    "                             shuffle=True)\n",
    "mini_batch_train_loader = du.DataLoader(dataset=torch.from_numpy(df[:df.shape[0]*8 // 10].values).float(),\n",
    "                             batch_size=mini_batch_size,\n",
    "                             shuffle=True)\n",
    "test_loader = du.DataLoader(dataset=torch.from_numpy(df[df.shape[0]*8//10:].values).float(),\n",
    "                             batch_size=df.shape[0],\n",
    "                             shuffle=True)\n",
    "\n",
    "Adam_optim = torch.optim.Adam(Adam_model.parameters(), lr=0.9)\n",
    "RMSprop_optim = torch.optim.RMSprop(RMSprop_model.parameters(), lr=0.9)\n",
    "\n",
    "# send model over to device\n",
    "vanilla_grad_model = vanilla_grad_model.to(device)\n",
    "mini_batch_grad_model = mini_batch_grad_model.to(device)\n",
    "Adam_model = Adam_model.to(device)\n",
    "RMSprop_model = RMSprop_model.to(device)\n",
    "vanilla_grad_model.train() \n",
    "mini_batch_grad_model.train()\n",
    "Adam_model.train() \n",
    "RMSprop_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two variants of gradient descent I chose to implement are vanilla and minibatch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Accuracy: 0.376825, Training Loss = nan\n",
      "Epoch 2, Training Accuracy: 0.639599, Training Loss = nan\n",
      "Epoch 3, Training Accuracy: 0.719891, Training Loss = nan\n",
      "Epoch 4, Training Accuracy: 0.934307, Training Loss = nan\n",
      "Epoch 5, Training Accuracy: 0.959854, Training Loss = nan\n",
      "Epoch 6, Training Accuracy: 0.961679, Training Loss = nan\n",
      "Epoch 7, Training Accuracy: 0.964416, Training Loss = nan\n",
      "Epoch 8, Training Accuracy: 0.964416, Training Loss = nan\n",
      "Epoch 9, Training Accuracy: 0.968978, Training Loss = nan\n",
      "Epoch 10, Training Accuracy: 0.966241, Training Loss = nan\n",
      "Epoch 11, Training Accuracy: 0.973540, Training Loss = nan\n",
      "Epoch 12, Training Accuracy: 0.967153, Training Loss = nan\n",
      "Epoch 13, Training Accuracy: 0.975365, Training Loss = nan\n",
      "Epoch 14, Training Accuracy: 0.972628, Training Loss = nan\n",
      "Epoch 15, Training Accuracy: 0.977190, Training Loss = nan\n",
      "Epoch 16, Training Accuracy: 0.969890, Training Loss = nan\n",
      "Epoch 17, Training Accuracy: 0.975365, Training Loss = nan\n",
      "Epoch 18, Training Accuracy: 0.972628, Training Loss = nan\n",
      "Epoch 19, Training Accuracy: 0.977190, Training Loss = nan\n",
      "Epoch 20, Training Accuracy: 0.975365, Training Loss = nan\n",
      "Testing Accuracy: 0.985455, Testing Loss = nan\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "vanilla gradient descent \n",
    "'''\n",
    "\n",
    "for epoch in range(1, epochs + 1):    \n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data) in enumerate(train_loader):  # batch size is the whole dataset\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = vanilla_grad_model(features)\n",
    "        running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        correct += torch.sum(pred == label)\n",
    "        update_grad(features, pred, label, vanilla_grad_model.parameters())\n",
    "        gradient_descent(vanilla_grad_model.parameters(), 0.01)\n",
    "    print(f\"Epoch {epoch}, Training Accuracy: {correct / len(train_loader.dataset):.6f}, Training Loss = {running_loss / len(train_loader.dataset):.6f}\")\n",
    "\n",
    "test_correct = 0\n",
    "test_running_loss = 0\n",
    "vanilla_grad_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data) in enumerate(test_loader):\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = vanilla_grad_model(features)\n",
    "        test_running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        test_correct += torch.sum(pred == label)\n",
    "print(f\"Testing Accuracy: {test_correct / len(test_loader.dataset):.6f}, Testing Loss = {test_running_loss / len(test_loader.dataset):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Accuracy: 0.954380, Training Loss = 0.253347\n",
      "Epoch 2, Training Accuracy: 0.990876, Training Loss = 0.183874\n",
      "Epoch 3, Training Accuracy: 0.986314, Training Loss = 0.178081\n",
      "Epoch 4, Training Accuracy: 0.985401, Training Loss = 0.175213\n",
      "Epoch 5, Training Accuracy: 0.989051, Training Loss = 0.175302\n",
      "Epoch 6, Training Accuracy: 0.989963, Training Loss = 0.176211\n",
      "Epoch 7, Training Accuracy: 0.987226, Training Loss = 0.173930\n",
      "Epoch 8, Training Accuracy: 0.989051, Training Loss = 0.177625\n",
      "Epoch 9, Training Accuracy: 0.989963, Training Loss = 0.173538\n",
      "Epoch 10, Training Accuracy: 0.986314, Training Loss = 0.175501\n",
      "Epoch 11, Training Accuracy: 0.985401, Training Loss = 0.168315\n",
      "Epoch 12, Training Accuracy: 0.980839, Training Loss = 0.171645\n",
      "Epoch 13, Training Accuracy: 0.978102, Training Loss = 0.170522\n",
      "Epoch 14, Training Accuracy: 0.983577, Training Loss = 0.168822\n",
      "Epoch 15, Training Accuracy: 0.981752, Training Loss = 0.167767\n",
      "Epoch 16, Training Accuracy: 0.985401, Training Loss = 0.170556\n",
      "Epoch 17, Training Accuracy: 0.987226, Training Loss = 0.168853\n",
      "Epoch 18, Training Accuracy: 0.988139, Training Loss = 0.171618\n",
      "Epoch 19, Training Accuracy: 0.984489, Training Loss = 0.174553\n",
      "Epoch 20, Training Accuracy: 0.979927, Training Loss = 0.167191\n",
      "Testing Accuracy: 0.992727, Testing Loss = 0.153552\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "mini batch gradient descent \n",
    "'''\n",
    "\n",
    "for epoch in range(1, epochs + 1):    \n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data) in enumerate(mini_batch_train_loader): # batch size is 64\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = mini_batch_grad_model(features)\n",
    "        running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        correct += torch.sum(pred == label)\n",
    "        update_grad(features, pred, label, mini_batch_grad_model.parameters())\n",
    "        gradient_descent(mini_batch_grad_model.parameters(), 0.01)\n",
    "    print(f\"Epoch {epoch}, Training Accuracy: {correct / len(train_loader.dataset):.6f}, Training Loss = {running_loss / len(train_loader.dataset):.6f}\")\n",
    "\n",
    "test_correct = 0\n",
    "test_running_loss = 0\n",
    "mini_batch_grad_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data) in enumerate(test_loader):\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = mini_batch_grad_model(features)\n",
    "        test_running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        test_correct += torch.sum(pred == label)\n",
    "print(f\"Testing Accuracy: {test_correct / len(test_loader.dataset):.6f}, Testing Loss = {test_running_loss / len(test_loader.dataset):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using torch.optim package to implement Adam and RMSprop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Accuracy: 0.465328, Training Loss = 5.649123\n",
      "Epoch 2, Training Accuracy: 0.690693, Training Loss = 1.142587\n",
      "Epoch 3, Training Accuracy: 0.789234, Training Loss = 0.805706\n",
      "Epoch 4, Training Accuracy: 0.786496, Training Loss = nan\n",
      "Epoch 5, Training Accuracy: 0.820255, Training Loss = nan\n",
      "Epoch 6, Training Accuracy: 0.837591, Training Loss = nan\n",
      "Epoch 7, Training Accuracy: 0.848540, Training Loss = nan\n",
      "Epoch 8, Training Accuracy: 0.867701, Training Loss = nan\n",
      "Epoch 9, Training Accuracy: 0.885949, Training Loss = nan\n",
      "Epoch 10, Training Accuracy: 0.889599, Training Loss = nan\n",
      "Epoch 11, Training Accuracy: 0.905109, Training Loss = nan\n",
      "Epoch 12, Training Accuracy: 0.914234, Training Loss = nan\n",
      "Epoch 13, Training Accuracy: 0.923358, Training Loss = nan\n",
      "Epoch 14, Training Accuracy: 0.935219, Training Loss = nan\n",
      "Epoch 15, Training Accuracy: 0.943431, Training Loss = nan\n",
      "Epoch 16, Training Accuracy: 0.954380, Training Loss = nan\n",
      "Epoch 17, Training Accuracy: 0.964416, Training Loss = nan\n",
      "Epoch 18, Training Accuracy: 0.973540, Training Loss = nan\n",
      "Epoch 19, Training Accuracy: 0.979927, Training Loss = nan\n",
      "Epoch 20, Training Accuracy: 0.980839, Training Loss = nan\n",
      "Testing Accuracy: 0.978182, Testing Loss = nan\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Adam Optimizer\n",
    "'''\n",
    "\n",
    "for epoch in range(1, epochs + 1):    \n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data) in enumerate(train_loader):\n",
    "        Adam_optim.zero_grad()\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = Adam_model(features)\n",
    "        running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        correct += torch.sum(pred == label)\n",
    "        update_grad(features, pred, label, Adam_model.parameters())\n",
    "        Adam_optim.step()\n",
    "    print(f\"Epoch {epoch}, Training Accuracy: {correct / len(train_loader.dataset):.6f}, Training Loss = {running_loss / len(train_loader.dataset):.6f}\")\n",
    "\n",
    "test_correct = 0\n",
    "test_running_loss = 0\n",
    "Adam_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data) in enumerate(test_loader):\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = Adam_model(features)\n",
    "        test_running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        test_correct += torch.sum(pred == label)\n",
    "print(f\"Testing Accuracy: {test_correct / len(test_loader.dataset):.6f}, Testing Loss = {test_running_loss / len(test_loader.dataset):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Accuracy: 0.660584, Training Loss = 0.526891\n",
      "Epoch 2, Training Accuracy: 0.505474, Training Loss = nan\n",
      "Epoch 3, Training Accuracy: 0.859489, Training Loss = nan\n",
      "Epoch 4, Training Accuracy: 0.897810, Training Loss = nan\n",
      "Epoch 5, Training Accuracy: 0.924270, Training Loss = nan\n",
      "Epoch 6, Training Accuracy: 0.947993, Training Loss = nan\n",
      "Epoch 7, Training Accuracy: 0.951642, Training Loss = nan\n",
      "Epoch 8, Training Accuracy: 0.963504, Training Loss = nan\n",
      "Epoch 9, Training Accuracy: 0.968066, Training Loss = nan\n",
      "Epoch 10, Training Accuracy: 0.969890, Training Loss = nan\n",
      "Epoch 11, Training Accuracy: 0.972628, Training Loss = nan\n",
      "Epoch 12, Training Accuracy: 0.976277, Training Loss = nan\n",
      "Epoch 13, Training Accuracy: 0.978102, Training Loss = nan\n",
      "Epoch 14, Training Accuracy: 0.981752, Training Loss = nan\n",
      "Epoch 15, Training Accuracy: 0.983577, Training Loss = nan\n",
      "Epoch 16, Training Accuracy: 0.983577, Training Loss = nan\n",
      "Epoch 17, Training Accuracy: 0.986314, Training Loss = nan\n",
      "Epoch 18, Training Accuracy: 0.986314, Training Loss = nan\n",
      "Epoch 19, Training Accuracy: 0.986314, Training Loss = nan\n",
      "Epoch 20, Training Accuracy: 0.989963, Training Loss = nan\n",
      "Testing Accuracy: 0.985455, Testing Loss = nan\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RMSprop Optimizer\n",
    "'''\n",
    "\n",
    "for epoch in range(1, epochs + 1):    \n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data) in enumerate(train_loader):\n",
    "        RMSprop_optim.zero_grad()\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = RMSprop_model(features)\n",
    "        running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        correct += torch.sum(pred == label)\n",
    "        update_grad(features, pred, label, RMSprop_model.parameters())\n",
    "        RMSprop_optim.step()\n",
    "    print(f\"Epoch {epoch}, Training Accuracy: {correct / len(train_loader.dataset):.6f}, Training Loss = {running_loss / len(train_loader.dataset):.6f}\")\n",
    "\n",
    "test_correct = 0\n",
    "test_running_loss = 0\n",
    "RMSprop_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data) in enumerate(test_loader):\n",
    "        features, label = data[:,:num_features].to(device), data[:,num_features].unsqueeze(1).to(device)\n",
    "        pred = RMSprop_model(features)\n",
    "        test_running_loss += loss_function(features, pred, label)\n",
    "        pred = torch.round(pred)\n",
    "        test_correct += torch.sum(pred == label)\n",
    "print(f\"Testing Accuracy: {test_correct / len(test_loader.dataset):.6f}, Testing Loss = {test_running_loss / len(test_loader.dataset):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare the accuracy of the Adam and RMSprop optimizers, we will find that RMSprop converges faster than Adam. After 50 epochs, RMSprop yields an accuracy of 98.5% while Adam yields an accuracy of 97.8%\n",
    "\n",
    "After 50 epochs, the testing accuracy of RMSprop is 98.5%, accuracy of Adam is 97.8%, the accuracy of Mini batch gradient descent is 99.3%, and the accuracy of vanilla gradient descent is 98.5%. While the accuracy of the optimizers is slightly lower than that of mini batch gradient descent, the testing accuracy of mini batch gradient descent oscillated a lot. On the other hand, the training of the optimizers was more stable. Therefore, optimization algorithms should be used for this task since it yelds more stable training and let us use higher learning rates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0be73a0e6356a5a1c38dc53f1e67790b18ed332d277068fed34d2daa61958429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
